import csv
import numpy as np
import random
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC, LinearSVC
from sklearn.model_selection import KFold, cross_val_score
import csv
import copy,math
from sklearn.metrics import precision_recall_fscore_support

class android(object):
	def __init__(self):
		ds = open('train_android.csv')
		rdr = csv.reader(ds)
		self.data = list(rdr)
		self.data = random.sample(self.data, len(self.data))
		self.data = np.array(self.data)
		ds1 = open('test_android.csv')
		rdr = csv.reader(ds1)
		self.testdata = list(rdr)
		self.testdata = random.sample(self.testdata, len(self.testdata))
		self.testdata = np.array(self.testdata)
		self.columns = np.shape(self.data)[1]-1
		self.rows = np.shape(self.data)[0]
		ds1.close()
		ds.close()

	def split_classLabel(self):
		cols = np.shape(self.data)[1]
		self.X = self.data[:,:cols-1]
		self.X = self.X.astype(np.float)
		self.y = self.data[:,cols-1]
		self.y = np.array(self.y)
		self.y = self.y.astype(np.int)
		self.y = np.ravel(self.y,order='C')

	def separateClass(self):
		classes_tuples = {}
		for i in range(len(self.data)):
			vector = self.data[i]
			vector = map(int, vector)
			if (vector[-1] not in classes_tuples):
				classes_tuples[vector[-1]] = []
			classes_tuples[(vector[-1])].append(vector)
		return classes_tuples

	def freq(self):
		classes_tuples = self.separateClass()
		self.freqc = [0]*2
		for i in range(len(classes_tuples)): 
			self.freqc[i] = np.sum(classes_tuples[i],axis=0)
		return self.freqc,classes_tuples

	def mutual_info(self):
		frequency,classes_tuples = self.freq()
		frequency = np.array(frequency).T
		c0 = len(classes_tuples[0])
		c1 = len(classes_tuples[1])
		N = self.rows
		mi = [0]*self.columns
		for i in range(len(frequency)-1):

			nfc0 = frequency[i][0]
			nfc1 = frequency[i][1]
			if nfc0 == 0:
				nfc0 = 1
			if nfc1 == 0:
				nfc1 = 1
			diff0 = (c0-nfc0)
			diff1 = (c1-nfc1)
			if diff0 == 0:
				diff0 = 1
			if diff1 == 0:
				diff1 = 1
			
			mi[i] = (float(nfc0)/N)*math.log((float(N*nfc0)/((nfc0+nfc1)*(c0))),math.e) + \
			(float(nfc1)/N)*math.log((float(N*nfc1)/((nfc0+nfc1)*(c1))),math.e) + \
			(float(c0-nfc0)/N)*math.log((float(N*diff0)/((c0+c1-nfc0-nfc1)*(c0))),math.e) + \
			(float(c1-nfc1)/N)*math.log((float(N*diff1)/((c0+c1-nfc0-nfc1)*(c1))),math.e)

		return np.array(mi),frequency


	def topFeatureList(self):
		b = open('dataset_weka2.csv', 'w')
		a = csv.writer(b)
		features = [i.strip() for i in open("features.txt").readlines()]
		features = np.array(features)
		mi,frequency = self.mutual_info()
		self.featureind = sorted(range(len(mi)), key=lambda i: mi[i], reverse=True)[:25]
		top25 = features[self.featureind]
		print mi[self.featureind]
		f_new=frequency[self.featureind]
		for i in range(0,len(top25)):
			print top25[i],frequency[i][0],frequency[i][1]

		c=open('attr.csv')
		d=csv.reader(c)
		attr=list(d)
		# print len(attr[0])
		featureind_new=copy.deepcopy(self.featureind)
		featureind_new.append(len(self.data[0])-1)
		# print len(featureind_new),featureind_new[25]
		attr_selected=[attr[0][i] for i in featureind_new]
		# print len(attr_selected)
		data=self.data[:,featureind_new]
		a.writerow(attr_selected)
		class_labels=['b','m']
		for row in data:
			row[25]=class_labels[int(row[25])%2]
		a.writerows(data)
		b.close()

	def Bayes(self):
		#training bayesian classifier
		cols = np.shape(self.data)[1]
		clf = GaussianNB()
		clf.fit(self.X[:,self.featureind],self.y)
		testData = self.testdata[:,self.featureind].astype(np.float)
		testTarget = np.array(self.testdata[:,cols-1]).astype(np.int)
		nbaccr = (clf.score(testData,testTarget))*100
		print "Accuracy with Naive Bayes", nbaccr
	
	
	def SVM(self):
		clf = SVC()
		clf.fit(self.X[:,self.featureind],self.y)
		testData = self.testdata[:,self.featureind].astype(np.float)
		testTarget = np.array(self.testdata[:,self.columns]).astype(np.int)
		svmaccr = (clf.score(testData,testTarget))*100
		print "Accuracy with SVM", svmaccr

		result=clf.predict(self.X[:,self.featureind])

		# print len(result),len(self.y)
		prf=precision_recall_fscore_support(self.y, result, average="binary")
		print "Precision",prf[0]
		print "Recall",prf[1]
		print "FScore",prf[2]

		model=SVC()
		accuracy_array = cross_val_score(model, self.X[:,self.featureind], self.y, cv=10)
		sumaccr = sum(accuracy_array)
		accuracy=(float(sumaccr) / len(accuracy_array))*100
		print "Accuracy with SVM", accuracy
	
	

adr = android()
adr.split_classLabel()
adr.topFeatureList()
adr.Bayes()
#adr.mutual_info()
adr.SVM()
